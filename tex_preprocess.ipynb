{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "class TexProcesser():\n",
    "    def __init__(self, latex_dir_path, output_path):\n",
    "        self.latex_folder = Path(latex_dir_path)\n",
    "        self.output_path = output_path\n",
    "        \n",
    "    def pipeline(self,):\n",
    "        self.processed_tex_dir = self.output_path + '/' + 'processed_tex'\n",
    "        self._preprocess(input_dir=self.latex_folder, output_dir=self.processed_tex_dir)\n",
    "        \n",
    "        output_csv_path = self.output_path + '/latex_info.csv'\n",
    "        self._extract_field_to_csv(output_csv_path=output_csv_path)\n",
    "        \n",
    "        # TODO:把文本批量转换为md文件\n",
    "        self._postprocess()\n",
    "        \n",
    "    def _preprocess(self, input_dir, output_dir):\n",
    "        '''\n",
    "        删除一些额外的表格和公式等等\n",
    "        '''\n",
    "\n",
    "        for file_path in sorted(input_dir.glob('**/*.tex')):\n",
    "        # latex = './NLP_LATEX_CORPUS/V04/V04N01-07.tex'\n",
    "            file_name = os.path.basename(file_path)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    latex_content = file.read()\n",
    "                print(f'processing {file_name} ...')\n",
    "                # 执行其他操作\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"UnicodeDecodeError: Failed to decode {file_path}. Skipping this file.\")\n",
    "                continue  # 跳过当前文件的处理\n",
    "            \n",
    "            # 删除\\begin{document}之前的所有内容\n",
    "            latex_content = re.sub(r'[\\s\\S]*?(?=\\\\begin\\{document\\})', '', latex_content, count=1, flags=re.DOTALL)\n",
    "                    \n",
    "            # 删除bibliographystyle之后的所有文本\n",
    "            # latex_content = re.sub(r'\\\\bibliographystyle\\{.*?\\}[\\s\\S]*', '', latex_content, flags=re.DOTALL)\n",
    "            \n",
    "            # 删除所有的图片\n",
    "            latex_content = re.sub(r'\\\\begin{figure}.*?\\\\end{figure}', '', latex_content, flags=re.DOTALL)\n",
    "            \n",
    "            # 删除所有的表格\n",
    "            latex_content = re.sub(r'\\\\begin{table}.*?\\\\end{table}', '', latex_content, flags=re.DOTALL)\n",
    "            latex_content = re.sub(r'\\\\begin{tabular}.*?\\\\end{tabular}', '', latex_content, flags=re.DOTALL)\n",
    "            \n",
    "            # 替换引用\\ref{...}文本为[...]\n",
    "            latex_content = re.sub(r'\\\\ref\\{([^{}]*)\\}', r'[\\1]', latex_content, flags=re.DOTALL)\n",
    "            \n",
    "            # 删除格式调整符号\n",
    "            # latex_content = re.sub(r'\\\\hspace\\*\\{[^{}]*\\}', '', latex_content, flags=re.DOTALL)\n",
    "            # latex_content = re.sub(r'\\\\vspace\\*\\{[^{}]*\\}', '', latex_content, flags=re.DOTALL)        \n",
    "        \n",
    "            # 删除所有的标签\\label{...}\n",
    "            latex_content = re.sub(r'\\\\label\\{.*?\\}', '', latex_content, flags=re.DOTALL)\n",
    "            \n",
    "            # 替换掉文本中有\\underline{...}的内容            \n",
    "            # latex_content = re.sub(r'\\\\underline\\{([^{}]*)\\}', r'\\1', latex_content, flags=re.DOTALL)            \n",
    "                                    \n",
    "            # 替换掉所有文献引用为@xcite\n",
    "            latex_content = re.sub(r'\\\\cite\\{.*?\\}', '@xcite', latex_content, flags=re.DOTALL)\n",
    "            \n",
    "            # 将所有的公式都替换为@xmath0, @xmath1, @xmath2, ...\n",
    "            formula_count = 0\n",
    "            def replace_formula(match):\n",
    "                nonlocal formula_count\n",
    "                new_formula = f'@xmath{formula_count}'\n",
    "                formula_count += 1\n",
    "                return new_formula\n",
    "            \n",
    "            latex_content = re.sub(r'\\$.*?\\$', replace_formula, latex_content, flags=re.DOTALL)\n",
    "\n",
    "            # 删除所有脚注\n",
    "            # NOTE: 必须在替换公式之后在进行删除，否则会引发冲突\n",
    "            # latex_content = re.sub(r'\\\\footnote\\{.*?\\}', '', latex_content, flags=re.DOTALL)\n",
    "            # latex_content = re.sub(r'(?s)\\\\footnote\\{.*?\\}', '', latex_content)\n",
    "            # latex_content = re.sub  (r'\\\\footnotemark', '', latex_content, flags=re.DOTALL)\n",
    "            # latex_content = re.sub(r'\\\\footnotetext\\{.*?\\}', '', latex_content, flags=re.DOTALL)       \n",
    "            \n",
    "            # # 使用正则表达式找到最后一个 \\section{} 的位置并删除其后的内容\n",
    "            # match_sections = [m.end() for m in re.finditer(r'\\\\section\\{.*?\\}', latex_content)]  # 查找所有 \\section{} 的位置\n",
    "            # if match_sections:\n",
    "            #     last_section_index = match_sections[-1]  \n",
    "            #     content_after_section = latex_content[last_section_index:]  # 获取最后一个 \\section{} 之后的内容\n",
    "\n",
    "            #     match_next_unknown = re.search(r'\\n\\\\[a-zA-Z]+\\{.*?\\}', content_after_section)  # 寻找下一个未知标记\n",
    "            #     if match_next_unknown:\n",
    "            #         next_unknown_index = last_section_index + match_next_unknown.start()  # 获取下一个未知标记的位置\n",
    "            #         latex_content = latex_content[:next_unknown_index]  # 保留标记之前的内容\n",
    "            \n",
    "            # # 在文章的末尾添加\\end{document}\n",
    "            # latex_content += '\\n\\\\end{document}'\n",
    "            \n",
    "            # 删除\\acknowledgment\n",
    "            # latex_content = re.sub(r'\\\\acknowledgment.*?(?=\\\\end\\{document\\})', '', latex_content, flags=re.DOTALL)\n",
    "            \n",
    "            # 将处理后的内容保存到新文件中\n",
    "            output_file = output_dir + '/' + file_name\n",
    "            with open(output_file, 'w', encoding='utf-8') as file:\n",
    "                file.write(latex_content)    \n",
    "                 \n",
    "    def _extract_field_to_csv(self, output_csv_path=None):\n",
    "        '''\n",
    "        extract title, etitle, jabstract, eabstract ... from latex files\n",
    "        '''\n",
    "        \n",
    "        # 定义csv文件的表头\n",
    "        output_csv_path = Path(output_csv_path)\n",
    "        csv_header = ['file_name', 'title', 'etitle', 'jabstract', 'eabstract', 'section_names',\n",
    "                      'sec_intro', 'sec_method', 'sec_result', 'sec_conclusion',\n",
    "                      'abs_intro', 'abs_method', 'abs_result', 'abs_conclusion']\n",
    "        \n",
    "        with open(output_csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=csv_header)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for file_path in sorted(self.latex_folder.glob('**/*.tex')):\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        latex_content = file.read()\n",
    "                    print(f'processing {file_path} ...')\n",
    "                except UnicodeDecodeError:\n",
    "                    print(f\"UnicodeDecodeError: Failed to decode {file_path}. Skipping this file.\")\n",
    "                    continue\n",
    "                    \n",
    "                matches = self._extract_info(latex_content=latex_content)\n",
    "                matches['file_name'] = file_path.name\n",
    "                \n",
    "                extra_columns = [\n",
    "                    'sec_intro', 'sec_method', 'sec_result', 'sec_conclusion',\n",
    "                    'abs_intro', 'abs_method', 'abs_result', 'abs_conclusion'\n",
    "                ]\n",
    "                for column in extra_columns:\n",
    "                    matches[column] = ''\n",
    "                \n",
    "                writer.writerow(matches)\n",
    "        \n",
    "    def _extract_info(self, latex_content=None):\n",
    "        \n",
    "        patterns = {\n",
    "            # TODO: title 和 jtitle 有时候会同时出现，需要处理\n",
    "            'title': re.compile(r'\\\\title\\{(.*?)\\}', re.DOTALL),\n",
    "            'etitle': re.compile(r'\\\\etitle\\{(.*?)\\}', re.DOTALL),\n",
    "            'jabstract': re.compile(r'\\\\jabstract\\{(.*?)\\}', re.DOTALL),\n",
    "            'eabstract': re.compile(r'\\\\eabstract\\{(.*?)\\}', re.DOTALL),     \n",
    "            'section_names': re.compile(r'\\\\section\\{(.*?)\\}', re.DOTALL),                 \n",
    "        }\n",
    "        \n",
    "        matches = {key: '' if key != 'section_names' else [] for key in patterns.keys()}\n",
    "        \n",
    "        for key, pattern in patterns.items():\n",
    "            matches[key] = pattern.findall(latex_content)\n",
    "            \n",
    "            if key == 'section_names':\n",
    "                matches[key] = [value.strip() for value in matches[key]]  # 移除首尾空白并存储在列表中\n",
    "                matches[key] = list(filter(None, matches[key]))  # 移除空字符串\n",
    "            \n",
    "            if key != 'section_names' and matches[key]:\n",
    "                matches[key] = re.sub(r'\\s*\\\\\\\\\\n\\s*', ' ', matches[key][0]).strip()\n",
    "            elif key != 'section_names':\n",
    "                matches[key] = ''\n",
    "\n",
    "        return matches\n",
    "    \n",
    "    def _postprocess(self):\n",
    "        \"\"\"\n",
    "        convert all processed tex files to markdown files\n",
    "        \"\"\"\n",
    "        markdown_output_dir = Path(self.output_path) / 'markdown'\n",
    "        markdown_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for file_path in sorted(Path(self.processed_tex_dir).glob('*.tex')):\n",
    "            md_output_path = markdown_output_dir / file_path.name.replace('.tex', '.txt')\n",
    "\n",
    "            try:\n",
    "                subprocess.run([\"pandoc\", str(file_path), \"-o\", str(md_output_path)])\n",
    "                print(f\"Converted {file_path} to Markdown: {md_output_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Conversion failed for {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_processer = TexProcesser(latex_dir_path='./data/NLP_LATEX_CORPUS/', output_path='./data')\n",
    "tex_processer.pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/latex_info.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NLP_JP_CORPUS.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./NLP_JP_CORPUS_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>etitle</th>\n",
       "      <th>jabstract</th>\n",
       "      <th>eabstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>sec_intro</th>\n",
       "      <th>sec_method</th>\n",
       "      <th>sec_result</th>\n",
       "      <th>sec_conclusion</th>\n",
       "      <th>abs_bg</th>\n",
       "      <th>abs_method</th>\n",
       "      <th>abs_result</th>\n",
       "      <th>abs_conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V01N01-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>表層表現中の情報に基づく文章構造の自動抽出</td>\n",
       "      <td>Automatic Detection of Discourse Structure by ...</td>\n",
       "      <td>テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...</td>\n",
       "      <td>To understand a text or dialogue, one must tra...</td>\n",
       "      <td>['はじめに', '文章構造のモデルと結束関係', '文章構造の自動抽出', '実験と考察'...</td>\n",
       "      <td>テキストや談話を理解するためには，文章構造の理解，すなわち各文が\\n他のどの文とどのような関...</td>\n",
       "      <td>従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...</td>\n",
       "      <td>実験には科学雑誌サイエンスのテキスト，\\n「科学技術のためのコンピューター」(Vol.17,...</td>\n",
       "      <td>本論文では，手がかり表現，語連鎖，文間の類似性，という\\n表層表現中の3つ情報に基づいて文章...</td>\n",
       "      <td>テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...</td>\n",
       "      <td>本論文では，知識に基づく文理解という処理を行なわずに，表層表現中の種々の情報を用いることによ...</td>\n",
       "      <td>実験の結果これらの情報を組み合わせて利用することにより\\n科学技術文の文章構造のかなりの部分...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V01N01-02.tex</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>A Comparative Study of Automatic Extraction of...</td>\n",
       "      <td></td>\n",
       "      <td>While corpus-based studies are now becoming a ...</td>\n",
       "      <td>['Introduction', 'Importance of Collocational ...</td>\n",
       "      <td>Recent rapid advances in computer technology, ...</td>\n",
       "      <td>In the past, several approaches have been prop...</td>\n",
       "      <td>In our experiments, the ADD (ATR Dialogue Data...</td>\n",
       "      <td>With the growing availability of large textual...</td>\n",
       "      <td>While corpus-based studies are now becoming a ...</td>\n",
       "      <td>In this paper, we are primarily concerned with...</td>\n",
       "      <td>Comparative experiments are made between the t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V01N01-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>並列構造の検出に基づく長い日本語文の構文解析</td>\n",
       "      <td>A Syntactic Analysis Method of Long Japanese S...</td>\n",
       "      <td>従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...</td>\n",
       "      <td>Conventional parsing methods can not analyze l...</td>\n",
       "      <td>['はじめに', '並列構造の検出と文の簡単化', '係り受け解析', '文解析の結果とその...</td>\n",
       "      <td># はじめに\\n\\n従来の構文解析法は基本的に句構造文法あるいは格文法をその拠り所としてきた...</td>\n",
       "      <td># 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...</td>\n",
       "      <td># 文解析の結果とその評価\\n\\n本手法による文解析の実験をテストサンプルの150文に対して...</td>\n",
       "      <td># おわりに\\n\\n従来方式の構文解析では長い文の中に多く存在する並列構造を正しく認識する\\...</td>\n",
       "      <td>従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...</td>\n",
       "      <td>本論文では，そのようにして検出した並列構造の情報を利用して\\n構文解析を行なう手法を示す．\\...</td>\n",
       "      <td>各部分の係り受け解析としては，基本的に，\\n係り受け関係の非交差条件を満たした上で各文節が係...</td>\n",
       "      <td>我々は，このような考え方に基づき，長い文の中に多く存在する並列構造が\\n文節列同士の類似性を...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V01N01-04.tex</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>A System for Finding Translation Patterns by C...</td>\n",
       "      <td></td>\n",
       "      <td>When the example-based approach is used for ma...</td>\n",
       "      <td>['Introduction', 'System Overview', 'Example-B...</td>\n",
       "      <td>The example-based approach (EBA), an emerging ...</td>\n",
       "      <td>The system flow of  is shown in . An input Jap...</td>\n",
       "      <td></td>\n",
       "      <td>Strong recent interest in corpus-based process...</td>\n",
       "      <td>When the example-based approach is used for ma...</td>\n",
       "      <td>This\\npaper describes a system for finding par...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V02N01-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>日英機械翻訳における利用者登録語の意味属性の自動推定</td>\n",
       "      <td>Automatic Determination of Semantic Attributes...</td>\n",
       "      <td>機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...</td>\n",
       "      <td>User dictionaries are important for practical ...</td>\n",
       "      <td>['はじめに', 'システム辞書と利用者辞書', '意味属性推定の方法', '意味属性推定精...</td>\n",
       "      <td># はじめに\\n\\n機械翻訳システムを使用する時, 利用者はシステム辞書に登録されていない\\...</td>\n",
       "      <td># 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...</td>\n",
       "      <td># 意味属性推定精度の評価\\n\\n## 実験の条件\\n\\n表\\[tab:3\\]に示すような新...</td>\n",
       "      <td>## 考察\\n\\n### 訳文品質向上効果について\\n\\n最適意味属性を決定する繰り返し実験...</td>\n",
       "      <td>機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...</td>\n",
       "      <td>そこで本論文では, 利用者が登録したい日本語名詞 (複合名詞を含む) と\\n英語訳語を与える...</td>\n",
       "      <td>本方式を, 新聞記事102文とソフトウエア設計書105文\\nの翻訳に必要な利用者辞書作成に適...</td>\n",
       "      <td>以上の結果, 利用者辞書\\n作成への単語の登録において, 最も熟練度の要求される単語意味属性...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>V26N03-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>事前学習された文の分散表現を用いた機械翻訳の自動評価</td>\n",
       "      <td>Metric for Automatic Machine Translation Evalu...</td>\n",
       "      <td>本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...</td>\n",
       "      <td>This study describes a segment-level metric fo...</td>\n",
       "      <td>['はじめに', '関連研究', '事前学習された文の分散表現を用いた機械翻訳の自動評価',...</td>\n",
       "      <td># はじめに\\n\\n本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．\\...</td>\n",
       "      <td># 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...</td>\n",
       "      <td># 評価実験\\n\\n本節では，WMT Metrics Shared\\nTaskにおける人手の...</td>\n",
       "      <td># 分析\\n\\n## 訓練データの文対数と性能の関係\\n\\n本節では，WMT-2017のlv...</td>\n",
       "      <td>本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...</td>\n",
       "      <td>そこで本研究では，文全体の大域的な情報を考慮するために，事前学習された文の分散表現を用いる機...</td>\n",
       "      <td>WMT-2017 Metrics Shared Taskにおける翻訳品質のラベル付きデータセ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>V26N03-04.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>単語埋め込みに基づくサプライザル</td>\n",
       "      <td>Surprisal through Word Embeddings</td>\n",
       "      <td>ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...</td>\n",
       "      <td>The concept of surprisal was proposed by Hale ...</td>\n",
       "      <td>['はじめに', '前提', '分析手法', '結果と考察', 'おわりに', '分析結果（...</td>\n",
       "      <td># はじめに\\n\\n本研究では眼球運動に基づき文の読み時間を推定し，ヒトの文処理機構の解明を...</td>\n",
       "      <td># 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...</td>\n",
       "      <td># 結果と考察\\n\\n表 \\[tbl:result\\] に各モデルの分析結果を示す．詳細な結...</td>\n",
       "      <td># おわりに\\n\\n本研究では，日本語の読み時間の推定のために単語埋め込みを用いることを提案...</td>\n",
       "      <td>ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...</td>\n",
       "      <td>本論文では，この問題を解決するために単語埋め込みを用いる．skip-gram の単語埋め込み...</td>\n",
       "      <td></td>\n",
       "      <td>さらに，skip-gram の単語埋め込みに基づいて構成した文節のベクトルのノルムが，日本語...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>V26N04-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>複単語表現を考慮した依存構造コーパスの構築と解析</td>\n",
       "      <td>Construction and Analysis of Multiword Express...</td>\n",
       "      <td>複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...</td>\n",
       "      <td>Multiword expressions (MWEs) consist of multip...</td>\n",
       "      <td>['はじめに', 'MWEを考慮した依存構造コーパスの構築', '連続MWEを考慮した依存構...</td>\n",
       "      <td># はじめに\\n\\n複単語表現 (MWE)\\nは，統語的もしくは意味的な単位として扱う必要が...</td>\n",
       "      <td># MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...</td>\n",
       "      <td># 連続MWEを考慮した依存構造解析，およびVMWE認識を行うモデルの評価実験\\n\\n本章で...</td>\n",
       "      <td># 結論\\n\\n本研究では，複合機能語と形容詞MWEの双方を考慮した依存構造コーパスをOnt...</td>\n",
       "      <td>複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...</td>\n",
       "      <td>広範囲の連続MWEを依存構造で考慮するために，本稿では Ontonotes コーパスに対して...</td>\n",
       "      <td>実験の結果，連続MWE認識ではパイプラインモデルとマルチタスクモデルがほぼ同等のF値を示し，...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>V26N04-02.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>多義語分散表現の文脈化</td>\n",
       "      <td>Contextualized Multi-Sense Word Embedding</td>\n",
       "      <td>近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...</td>\n",
       "      <td>Currently, distributed word representations ar...</td>\n",
       "      <td>['はじめに', '関連研究', '提案手法', '実験設定', '文脈中での単語間の意味的...</td>\n",
       "      <td># はじめに\\n\\n単語を密ベクトルで表現する単語分散表現 \\@xciteが，機械翻訳\\n\\...</td>\n",
       "      <td># 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...</td>\n",
       "      <td># 実験設定\\n\\n提案手法の有効性を検証するために，文脈中での単語間の意味的類似度推定タス...</td>\n",
       "      <td># DMSEの分析\\n\\n## 語彙的換言タスクにおける意味的類似度推定手法の比較\\n\\n表...</td>\n",
       "      <td>近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...</td>\n",
       "      <td>そこで，本研究では各単語に対してより粒度の細かい複数の分散表現を生成するための 2 つの手法...</td>\n",
       "      <td>単語間の意味的類似度推定タスクおよび語彙的換言タスクにおける評価実験の結果，より細かい粒度で...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>V26N04-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>ニューラル機械翻訳における単語報酬モデルに基づく対訳辞書の利用</td>\n",
       "      <td>Word Rewarding Model Using a Bilingual Diction...</td>\n",
       "      <td>ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...</td>\n",
       "      <td>Even though outputs of neural machine translat...</td>\n",
       "      <td>['はじめに', '注意機構付きニューラル機械翻訳', '単語報酬モデル', '実験設定',...</td>\n",
       "      <td># はじめに\\n\\nニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に...</td>\n",
       "      <td># 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...</td>\n",
       "      <td># 実験設定\\n\\n本稿では単語報酬モデルの性能を評価するため，日本語から英語，英語から日本...</td>\n",
       "      <td># おわりに\\n\\n本稿ではニューラル機械翻訳における単語報酬モデルによる対訳辞書の活用手法...</td>\n",
       "      <td>ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>提案手法は，テスト時のデコーディングの際に対訳辞書に存在する単語に報酬を与えることでそれらの...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name language                            title  \\\n",
       "0    V01N01-01.tex       jp            表層表現中の情報に基づく文章構造の自動抽出   \n",
       "1    V01N01-02.tex       en                                    \n",
       "2    V01N01-03.tex       jp           並列構造の検出に基づく長い日本語文の構文解析   \n",
       "3    V01N01-04.tex       en                                    \n",
       "4    V02N01-01.tex       jp       日英機械翻訳における利用者登録語の意味属性の自動推定   \n",
       "..             ...      ...                              ...   \n",
       "527  V26N03-03.tex       jp       事前学習された文の分散表現を用いた機械翻訳の自動評価   \n",
       "528  V26N03-04.tex       jp                 単語埋め込みに基づくサプライザル   \n",
       "529  V26N04-01.tex       jp         複単語表現を考慮した依存構造コーパスの構築と解析   \n",
       "530  V26N04-02.tex       jp                      多義語分散表現の文脈化   \n",
       "531  V26N04-03.tex       jp  ニューラル機械翻訳における単語報酬モデルに基づく対訳辞書の利用   \n",
       "\n",
       "                                                etitle  \\\n",
       "0    Automatic Detection of Discourse Structure by ...   \n",
       "1    A Comparative Study of Automatic Extraction of...   \n",
       "2    A Syntactic Analysis Method of Long Japanese S...   \n",
       "3    A System for Finding Translation Patterns by C...   \n",
       "4    Automatic Determination of Semantic Attributes...   \n",
       "..                                                 ...   \n",
       "527  Metric for Automatic Machine Translation Evalu...   \n",
       "528                  Surprisal through Word Embeddings   \n",
       "529  Construction and Analysis of Multiword Express...   \n",
       "530          Contextualized Multi-Sense Word Embedding   \n",
       "531  Word Rewarding Model Using a Bilingual Diction...   \n",
       "\n",
       "                                             jabstract  \\\n",
       "0    テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...   \n",
       "1                                                        \n",
       "2    従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...   \n",
       "3                                                        \n",
       "4    機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...   \n",
       "..                                                 ...   \n",
       "527  本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...   \n",
       "528  ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...   \n",
       "529  複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...   \n",
       "530  近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...   \n",
       "531  ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...   \n",
       "\n",
       "                                             eabstract  \\\n",
       "0    To understand a text or dialogue, one must tra...   \n",
       "1    While corpus-based studies are now becoming a ...   \n",
       "2    Conventional parsing methods can not analyze l...   \n",
       "3    When the example-based approach is used for ma...   \n",
       "4    User dictionaries are important for practical ...   \n",
       "..                                                 ...   \n",
       "527  This study describes a segment-level metric fo...   \n",
       "528  The concept of surprisal was proposed by Hale ...   \n",
       "529  Multiword expressions (MWEs) consist of multip...   \n",
       "530  Currently, distributed word representations ar...   \n",
       "531  Even though outputs of neural machine translat...   \n",
       "\n",
       "                                         section_names  \\\n",
       "0    ['はじめに', '文章構造のモデルと結束関係', '文章構造の自動抽出', '実験と考察'...   \n",
       "1    ['Introduction', 'Importance of Collocational ...   \n",
       "2    ['はじめに', '並列構造の検出と文の簡単化', '係り受け解析', '文解析の結果とその...   \n",
       "3    ['Introduction', 'System Overview', 'Example-B...   \n",
       "4    ['はじめに', 'システム辞書と利用者辞書', '意味属性推定の方法', '意味属性推定精...   \n",
       "..                                                 ...   \n",
       "527  ['はじめに', '関連研究', '事前学習された文の分散表現を用いた機械翻訳の自動評価',...   \n",
       "528  ['はじめに', '前提', '分析手法', '結果と考察', 'おわりに', '分析結果（...   \n",
       "529  ['はじめに', 'MWEを考慮した依存構造コーパスの構築', '連続MWEを考慮した依存構...   \n",
       "530  ['はじめに', '関連研究', '提案手法', '実験設定', '文脈中での単語間の意味的...   \n",
       "531  ['はじめに', '注意機構付きニューラル機械翻訳', '単語報酬モデル', '実験設定',...   \n",
       "\n",
       "                                             sec_intro  \\\n",
       "0    テキストや談話を理解するためには，文章構造の理解，すなわち各文が\\n他のどの文とどのような関...   \n",
       "1    Recent rapid advances in computer technology, ...   \n",
       "2    # はじめに\\n\\n従来の構文解析法は基本的に句構造文法あるいは格文法をその拠り所としてきた...   \n",
       "3    The example-based approach (EBA), an emerging ...   \n",
       "4    # はじめに\\n\\n機械翻訳システムを使用する時, 利用者はシステム辞書に登録されていない\\...   \n",
       "..                                                 ...   \n",
       "527  # はじめに\\n\\n本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．\\...   \n",
       "528  # はじめに\\n\\n本研究では眼球運動に基づき文の読み時間を推定し，ヒトの文処理機構の解明を...   \n",
       "529  # はじめに\\n\\n複単語表現 (MWE)\\nは，統語的もしくは意味的な単位として扱う必要が...   \n",
       "530  # はじめに\\n\\n単語を密ベクトルで表現する単語分散表現 \\@xciteが，機械翻訳\\n\\...   \n",
       "531  # はじめに\\n\\nニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に...   \n",
       "\n",
       "                                            sec_method  \\\n",
       "0    従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...   \n",
       "1    In the past, several approaches have been prop...   \n",
       "2    # 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...   \n",
       "3    The system flow of  is shown in . An input Jap...   \n",
       "4    # 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...   \n",
       "..                                                 ...   \n",
       "527  # 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...   \n",
       "528  # 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...   \n",
       "529  # MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...   \n",
       "530  # 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...   \n",
       "531  # 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...   \n",
       "\n",
       "                                            sec_result  \\\n",
       "0    実験には科学雑誌サイエンスのテキスト，\\n「科学技術のためのコンピューター」(Vol.17,...   \n",
       "1    In our experiments, the ADD (ATR Dialogue Data...   \n",
       "2    # 文解析の結果とその評価\\n\\n本手法による文解析の実験をテストサンプルの150文に対して...   \n",
       "3                                                        \n",
       "4    # 意味属性推定精度の評価\\n\\n## 実験の条件\\n\\n表\\[tab:3\\]に示すような新...   \n",
       "..                                                 ...   \n",
       "527  # 評価実験\\n\\n本節では，WMT Metrics Shared\\nTaskにおける人手の...   \n",
       "528  # 結果と考察\\n\\n表 \\[tbl:result\\] に各モデルの分析結果を示す．詳細な結...   \n",
       "529  # 連続MWEを考慮した依存構造解析，およびVMWE認識を行うモデルの評価実験\\n\\n本章で...   \n",
       "530  # 実験設定\\n\\n提案手法の有効性を検証するために，文脈中での単語間の意味的類似度推定タス...   \n",
       "531  # 実験設定\\n\\n本稿では単語報酬モデルの性能を評価するため，日本語から英語，英語から日本...   \n",
       "\n",
       "                                        sec_conclusion  \\\n",
       "0    本論文では，手がかり表現，語連鎖，文間の類似性，という\\n表層表現中の3つ情報に基づいて文章...   \n",
       "1    With the growing availability of large textual...   \n",
       "2    # おわりに\\n\\n従来方式の構文解析では長い文の中に多く存在する並列構造を正しく認識する\\...   \n",
       "3    Strong recent interest in corpus-based process...   \n",
       "4    ## 考察\\n\\n### 訳文品質向上効果について\\n\\n最適意味属性を決定する繰り返し実験...   \n",
       "..                                                 ...   \n",
       "527  # 分析\\n\\n## 訓練データの文対数と性能の関係\\n\\n本節では，WMT-2017のlv...   \n",
       "528  # おわりに\\n\\n本研究では，日本語の読み時間の推定のために単語埋め込みを用いることを提案...   \n",
       "529  # 結論\\n\\n本研究では，複合機能語と形容詞MWEの双方を考慮した依存構造コーパスをOnt...   \n",
       "530  # DMSEの分析\\n\\n## 語彙的換言タスクにおける意味的類似度推定手法の比較\\n\\n表...   \n",
       "531  # おわりに\\n\\n本稿ではニューラル機械翻訳における単語報酬モデルによる対訳辞書の活用手法...   \n",
       "\n",
       "                                                abs_bg  \\\n",
       "0    テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...   \n",
       "1    While corpus-based studies are now becoming a ...   \n",
       "2    従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...   \n",
       "3    When the example-based approach is used for ma...   \n",
       "4    機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...   \n",
       "..                                                 ...   \n",
       "527  本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...   \n",
       "528  ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...   \n",
       "529  複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...   \n",
       "530  近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...   \n",
       "531  ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...   \n",
       "\n",
       "                                            abs_method  \\\n",
       "0    本論文では，知識に基づく文理解という処理を行なわずに，表層表現中の種々の情報を用いることによ...   \n",
       "1    In this paper, we are primarily concerned with...   \n",
       "2    本論文では，そのようにして検出した並列構造の情報を利用して\\n構文解析を行なう手法を示す．\\...   \n",
       "3    This\\npaper describes a system for finding par...   \n",
       "4    そこで本論文では, 利用者が登録したい日本語名詞 (複合名詞を含む) と\\n英語訳語を与える...   \n",
       "..                                                 ...   \n",
       "527  そこで本研究では，文全体の大域的な情報を考慮するために，事前学習された文の分散表現を用いる機...   \n",
       "528  本論文では，この問題を解決するために単語埋め込みを用いる．skip-gram の単語埋め込み...   \n",
       "529  広範囲の連続MWEを依存構造で考慮するために，本稿では Ontonotes コーパスに対して...   \n",
       "530  そこで，本研究では各単語に対してより粒度の細かい複数の分散表現を生成するための 2 つの手法...   \n",
       "531                                                      \n",
       "\n",
       "                                            abs_result  \\\n",
       "0    実験の結果これらの情報を組み合わせて利用することにより\\n科学技術文の文章構造のかなりの部分...   \n",
       "1    Comparative experiments are made between the t...   \n",
       "2    各部分の係り受け解析としては，基本的に，\\n係り受け関係の非交差条件を満たした上で各文節が係...   \n",
       "3                                                        \n",
       "4    本方式を, 新聞記事102文とソフトウエア設計書105文\\nの翻訳に必要な利用者辞書作成に適...   \n",
       "..                                                 ...   \n",
       "527  WMT-2017 Metrics Shared Taskにおける翻訳品質のラベル付きデータセ...   \n",
       "528                                                      \n",
       "529  実験の結果，連続MWE認識ではパイプラインモデルとマルチタスクモデルがほぼ同等のF値を示し，...   \n",
       "530  単語間の意味的類似度推定タスクおよび語彙的換言タスクにおける評価実験の結果，より細かい粒度で...   \n",
       "531                                                      \n",
       "\n",
       "                                        abs_conclusion  \n",
       "0                                                       \n",
       "1                                                       \n",
       "2    我々は，このような考え方に基づき，長い文の中に多く存在する並列構造が\\n文節列同士の類似性を...  \n",
       "3                                                       \n",
       "4    以上の結果, 利用者辞書\\n作成への単語の登録において, 最も熟練度の要求される単語意味属性...  \n",
       "..                                                 ...  \n",
       "527                                                     \n",
       "528  さらに，skip-gram の単語埋め込みに基づいて構成した文節のベクトルのノルムが，日本語...  \n",
       "529                                                     \n",
       "530                                                     \n",
       "531  提案手法は，テスト時のデコーディングの際に対訳辞書に存在する単語に報酬を与えることでそれらの...  \n",
       "\n",
       "[532 rows x 15 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna('', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>etitle</th>\n",
       "      <th>jabstract</th>\n",
       "      <th>eabstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>sec_intro</th>\n",
       "      <th>sec_method</th>\n",
       "      <th>sec_result</th>\n",
       "      <th>sec_conclusion</th>\n",
       "      <th>abs_bg</th>\n",
       "      <th>abs_method</th>\n",
       "      <th>abs_result</th>\n",
       "      <th>abs_conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V01N01-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>表層表現中の情報に基づく文章構造の自動抽出</td>\n",
       "      <td>Automatic Detection of Discourse Structure by ...</td>\n",
       "      <td>テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...</td>\n",
       "      <td>To understand a text or dialogue, one must tra...</td>\n",
       "      <td>['はじめに', '文章構造のモデルと結束関係', '文章構造の自動抽出', '実験と考察'...</td>\n",
       "      <td>テキストや談話を理解するためには，文章構造の理解，すなわち各文が\\n他のどの文とどのような関...</td>\n",
       "      <td>従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...</td>\n",
       "      <td>実験には科学雑誌サイエンスのテキスト，\\n「科学技術のためのコンピューター」(Vol.17,...</td>\n",
       "      <td>本論文では，手がかり表現，語連鎖，文間の類似性，という\\n表層表現中の3つ情報に基づいて文章...</td>\n",
       "      <td>テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...</td>\n",
       "      <td>本論文では，知識に基づく文理解という処理を行なわずに，表層表現中の種々の情報を用いることによ...</td>\n",
       "      <td>実験の結果これらの情報を組み合わせて利用することにより\\n科学技術文の文章構造のかなりの部分...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V01N01-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>並列構造の検出に基づく長い日本語文の構文解析</td>\n",
       "      <td>A Syntactic Analysis Method of Long Japanese S...</td>\n",
       "      <td>従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...</td>\n",
       "      <td>Conventional parsing methods can not analyze l...</td>\n",
       "      <td>['はじめに', '並列構造の検出と文の簡単化', '係り受け解析', '文解析の結果とその...</td>\n",
       "      <td># はじめに\\n\\n従来の構文解析法は基本的に句構造文法あるいは格文法をその拠り所としてきた...</td>\n",
       "      <td># 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...</td>\n",
       "      <td># 文解析の結果とその評価\\n\\n本手法による文解析の実験をテストサンプルの150文に対して...</td>\n",
       "      <td># おわりに\\n\\n従来方式の構文解析では長い文の中に多く存在する並列構造を正しく認識する\\...</td>\n",
       "      <td>従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...</td>\n",
       "      <td>本論文では，そのようにして検出した並列構造の情報を利用して\\n構文解析を行なう手法を示す．\\...</td>\n",
       "      <td>各部分の係り受け解析としては，基本的に，\\n係り受け関係の非交差条件を満たした上で各文節が係...</td>\n",
       "      <td>我々は，このような考え方に基づき，長い文の中に多く存在する並列構造が\\n文節列同士の類似性を...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V02N01-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>日英機械翻訳における利用者登録語の意味属性の自動推定</td>\n",
       "      <td>Automatic Determination of Semantic Attributes...</td>\n",
       "      <td>機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...</td>\n",
       "      <td>User dictionaries are important for practical ...</td>\n",
       "      <td>['はじめに', 'システム辞書と利用者辞書', '意味属性推定の方法', '意味属性推定精...</td>\n",
       "      <td># はじめに\\n\\n機械翻訳システムを使用する時, 利用者はシステム辞書に登録されていない\\...</td>\n",
       "      <td># 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...</td>\n",
       "      <td># 意味属性推定精度の評価\\n\\n## 実験の条件\\n\\n表\\[tab:3\\]に示すような新...</td>\n",
       "      <td>## 考察\\n\\n### 訳文品質向上効果について\\n\\n最適意味属性を決定する繰り返し実験...</td>\n",
       "      <td>機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...</td>\n",
       "      <td>そこで本論文では, 利用者が登録したい日本語名詞 (複合名詞を含む) と\\n英語訳語を与える...</td>\n",
       "      <td>本方式を, 新聞記事102文とソフトウエア設計書105文\\nの翻訳に必要な利用者辞書作成に適...</td>\n",
       "      <td>以上の結果, 利用者辞書\\n作成への単語の登録において, 最も熟練度の要求される単語意味属性...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V02N01-02.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>主観的動機に関する意味および語用論的制約を利用した日本語複文の理解システム 〜「ので」「のに...</td>\n",
       "      <td>A zero anaphora resolution systemfor Japanese ...</td>\n",
       "      <td>我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...</td>\n",
       "      <td>Our aim is to construct a system which is able...</td>\n",
       "      <td>['はじめに', '日本語複文に関する制約および素性構造による表現', '制約変換による日本...</td>\n",
       "      <td># はじめに\\n\\n我々が目標とするのは，日本語の複文の理解システムである．このようなシステ...</td>\n",
       "      <td># 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...</td>\n",
       "      <td># 制約変換による日本語複文の意味解析システム\\n\\n以上のように，意味および語用論的役割の...</td>\n",
       "      <td># おわりに\\n\\n本論文では順接の「ので」による複文の解析を例にとり，日本語の複文の意味解...</td>\n",
       "      <td>我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...</td>\n",
       "      <td>この際には，ゼロ代名詞の照応の解析が重要な問題となるが，文献にあるように，本論文で扱う形式の...</td>\n",
       "      <td>そこで，日本語の複文に対する形態素解析や構文解析の結果を素性構造で記述し，こ\\nの結果に対し...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V02N01-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>文章内構造を複合的に利用した論説文要約システムGREEN</td>\n",
       "      <td>GREEN: An Experimental System Generating Summa...</td>\n",
       "      <td>日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...</td>\n",
       "      <td>This paper describes an experimental system fo...</td>\n",
       "      <td>['はじめに', 'システム構成', '要約文選択', '文要約解析', '段落分け解析',...</td>\n",
       "      <td># はじめに\\n\\n本論文では日本語の論説文を対象にした要約文章作成実験システム[^1] (...</td>\n",
       "      <td># システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...</td>\n",
       "      <td># 文要約解析\\n\\n文中の修飾句を削減することにより, 一文内での要約を行う. 文の中心内...</td>\n",
       "      <td># 議論\\n\\nここでは, 機械処理した大量の要約結果の考察から得られた知見や明らかになっ\\...</td>\n",
       "      <td>日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...</td>\n",
       "      <td>本研究ではこの観点から, 日本語での様々な表層的特徴をできるだけ多く利用\\nして, 日本語文...</td>\n",
       "      <td>本稿では実際に計算機上で試作した論説文\\n要約システムに関して, これで用いられている論説文...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>V26N03-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>事前学習された文の分散表現を用いた機械翻訳の自動評価</td>\n",
       "      <td>Metric for Automatic Machine Translation Evalu...</td>\n",
       "      <td>本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...</td>\n",
       "      <td>This study describes a segment-level metric fo...</td>\n",
       "      <td>['はじめに', '関連研究', '事前学習された文の分散表現を用いた機械翻訳の自動評価',...</td>\n",
       "      <td># はじめに\\n\\n本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．\\...</td>\n",
       "      <td># 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...</td>\n",
       "      <td># 評価実験\\n\\n本節では，WMT Metrics Shared\\nTaskにおける人手の...</td>\n",
       "      <td># 分析\\n\\n## 訓練データの文対数と性能の関係\\n\\n本節では，WMT-2017のlv...</td>\n",
       "      <td>本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...</td>\n",
       "      <td>そこで本研究では，文全体の大域的な情報を考慮するために，事前学習された文の分散表現を用いる機...</td>\n",
       "      <td>WMT-2017 Metrics Shared Taskにおける翻訳品質のラベル付きデータセ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>V26N03-04.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>単語埋め込みに基づくサプライザル</td>\n",
       "      <td>Surprisal through Word Embeddings</td>\n",
       "      <td>ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...</td>\n",
       "      <td>The concept of surprisal was proposed by Hale ...</td>\n",
       "      <td>['はじめに', '前提', '分析手法', '結果と考察', 'おわりに', '分析結果（...</td>\n",
       "      <td># はじめに\\n\\n本研究では眼球運動に基づき文の読み時間を推定し，ヒトの文処理機構の解明を...</td>\n",
       "      <td># 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...</td>\n",
       "      <td># 結果と考察\\n\\n表 \\[tbl:result\\] に各モデルの分析結果を示す．詳細な結...</td>\n",
       "      <td># おわりに\\n\\n本研究では，日本語の読み時間の推定のために単語埋め込みを用いることを提案...</td>\n",
       "      <td>ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...</td>\n",
       "      <td>本論文では，この問題を解決するために単語埋め込みを用いる．skip-gram の単語埋め込み...</td>\n",
       "      <td></td>\n",
       "      <td>さらに，skip-gram の単語埋め込みに基づいて構成した文節のベクトルのノルムが，日本語...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>V26N04-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>複単語表現を考慮した依存構造コーパスの構築と解析</td>\n",
       "      <td>Construction and Analysis of Multiword Express...</td>\n",
       "      <td>複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...</td>\n",
       "      <td>Multiword expressions (MWEs) consist of multip...</td>\n",
       "      <td>['はじめに', 'MWEを考慮した依存構造コーパスの構築', '連続MWEを考慮した依存構...</td>\n",
       "      <td># はじめに\\n\\n複単語表現 (MWE)\\nは，統語的もしくは意味的な単位として扱う必要が...</td>\n",
       "      <td># MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...</td>\n",
       "      <td># 連続MWEを考慮した依存構造解析，およびVMWE認識を行うモデルの評価実験\\n\\n本章で...</td>\n",
       "      <td># 結論\\n\\n本研究では，複合機能語と形容詞MWEの双方を考慮した依存構造コーパスをOnt...</td>\n",
       "      <td>複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...</td>\n",
       "      <td>広範囲の連続MWEを依存構造で考慮するために，本稿では Ontonotes コーパスに対して...</td>\n",
       "      <td>実験の結果，連続MWE認識ではパイプラインモデルとマルチタスクモデルがほぼ同等のF値を示し，...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>V26N04-02.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>多義語分散表現の文脈化</td>\n",
       "      <td>Contextualized Multi-Sense Word Embedding</td>\n",
       "      <td>近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...</td>\n",
       "      <td>Currently, distributed word representations ar...</td>\n",
       "      <td>['はじめに', '関連研究', '提案手法', '実験設定', '文脈中での単語間の意味的...</td>\n",
       "      <td># はじめに\\n\\n単語を密ベクトルで表現する単語分散表現 \\@xciteが，機械翻訳\\n\\...</td>\n",
       "      <td># 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...</td>\n",
       "      <td># 実験設定\\n\\n提案手法の有効性を検証するために，文脈中での単語間の意味的類似度推定タス...</td>\n",
       "      <td># DMSEの分析\\n\\n## 語彙的換言タスクにおける意味的類似度推定手法の比較\\n\\n表...</td>\n",
       "      <td>近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...</td>\n",
       "      <td>そこで，本研究では各単語に対してより粒度の細かい複数の分散表現を生成するための 2 つの手法...</td>\n",
       "      <td>単語間の意味的類似度推定タスクおよび語彙的換言タスクにおける評価実験の結果，より細かい粒度で...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>V26N04-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>ニューラル機械翻訳における単語報酬モデルに基づく対訳辞書の利用</td>\n",
       "      <td>Word Rewarding Model Using a Bilingual Diction...</td>\n",
       "      <td>ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...</td>\n",
       "      <td>Even though outputs of neural machine translat...</td>\n",
       "      <td>['はじめに', '注意機構付きニューラル機械翻訳', '単語報酬モデル', '実験設定',...</td>\n",
       "      <td># はじめに\\n\\nニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に...</td>\n",
       "      <td># 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...</td>\n",
       "      <td># 実験設定\\n\\n本稿では単語報酬モデルの性能を評価するため，日本語から英語，英語から日本...</td>\n",
       "      <td># おわりに\\n\\n本稿ではニューラル機械翻訳における単語報酬モデルによる対訳辞書の活用手法...</td>\n",
       "      <td>ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>提案手法は，テスト時のデコーディングの際に対訳辞書に存在する単語に報酬を与えることでそれらの...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name language  \\\n",
       "0    V01N01-01.tex       jp   \n",
       "2    V01N01-03.tex       jp   \n",
       "4    V02N01-01.tex       jp   \n",
       "5    V02N01-02.tex       jp   \n",
       "6    V02N01-03.tex       jp   \n",
       "..             ...      ...   \n",
       "527  V26N03-03.tex       jp   \n",
       "528  V26N03-04.tex       jp   \n",
       "529  V26N04-01.tex       jp   \n",
       "530  V26N04-02.tex       jp   \n",
       "531  V26N04-03.tex       jp   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                表層表現中の情報に基づく文章構造の自動抽出   \n",
       "2                               並列構造の検出に基づく長い日本語文の構文解析   \n",
       "4                           日英機械翻訳における利用者登録語の意味属性の自動推定   \n",
       "5    主観的動機に関する意味および語用論的制約を利用した日本語複文の理解システム 〜「ので」「のに...   \n",
       "6                         文章内構造を複合的に利用した論説文要約システムGREEN   \n",
       "..                                                 ...   \n",
       "527                         事前学習された文の分散表現を用いた機械翻訳の自動評価   \n",
       "528                                   単語埋め込みに基づくサプライザル   \n",
       "529                           複単語表現を考慮した依存構造コーパスの構築と解析   \n",
       "530                                        多義語分散表現の文脈化   \n",
       "531                    ニューラル機械翻訳における単語報酬モデルに基づく対訳辞書の利用   \n",
       "\n",
       "                                                etitle  \\\n",
       "0    Automatic Detection of Discourse Structure by ...   \n",
       "2    A Syntactic Analysis Method of Long Japanese S...   \n",
       "4    Automatic Determination of Semantic Attributes...   \n",
       "5    A zero anaphora resolution systemfor Japanese ...   \n",
       "6    GREEN: An Experimental System Generating Summa...   \n",
       "..                                                 ...   \n",
       "527  Metric for Automatic Machine Translation Evalu...   \n",
       "528                  Surprisal through Word Embeddings   \n",
       "529  Construction and Analysis of Multiword Express...   \n",
       "530          Contextualized Multi-Sense Word Embedding   \n",
       "531  Word Rewarding Model Using a Bilingual Diction...   \n",
       "\n",
       "                                             jabstract  \\\n",
       "0    テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...   \n",
       "2    従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...   \n",
       "4    機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...   \n",
       "5    我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...   \n",
       "6    日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...   \n",
       "..                                                 ...   \n",
       "527  本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...   \n",
       "528  ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...   \n",
       "529  複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...   \n",
       "530  近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...   \n",
       "531  ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...   \n",
       "\n",
       "                                             eabstract  \\\n",
       "0    To understand a text or dialogue, one must tra...   \n",
       "2    Conventional parsing methods can not analyze l...   \n",
       "4    User dictionaries are important for practical ...   \n",
       "5    Our aim is to construct a system which is able...   \n",
       "6    This paper describes an experimental system fo...   \n",
       "..                                                 ...   \n",
       "527  This study describes a segment-level metric fo...   \n",
       "528  The concept of surprisal was proposed by Hale ...   \n",
       "529  Multiword expressions (MWEs) consist of multip...   \n",
       "530  Currently, distributed word representations ar...   \n",
       "531  Even though outputs of neural machine translat...   \n",
       "\n",
       "                                         section_names  \\\n",
       "0    ['はじめに', '文章構造のモデルと結束関係', '文章構造の自動抽出', '実験と考察'...   \n",
       "2    ['はじめに', '並列構造の検出と文の簡単化', '係り受け解析', '文解析の結果とその...   \n",
       "4    ['はじめに', 'システム辞書と利用者辞書', '意味属性推定の方法', '意味属性推定精...   \n",
       "5    ['はじめに', '日本語複文に関する制約および素性構造による表現', '制約変換による日本...   \n",
       "6    ['はじめに', 'システム構成', '要約文選択', '文要約解析', '段落分け解析',...   \n",
       "..                                                 ...   \n",
       "527  ['はじめに', '関連研究', '事前学習された文の分散表現を用いた機械翻訳の自動評価',...   \n",
       "528  ['はじめに', '前提', '分析手法', '結果と考察', 'おわりに', '分析結果（...   \n",
       "529  ['はじめに', 'MWEを考慮した依存構造コーパスの構築', '連続MWEを考慮した依存構...   \n",
       "530  ['はじめに', '関連研究', '提案手法', '実験設定', '文脈中での単語間の意味的...   \n",
       "531  ['はじめに', '注意機構付きニューラル機械翻訳', '単語報酬モデル', '実験設定',...   \n",
       "\n",
       "                                             sec_intro  \\\n",
       "0    テキストや談話を理解するためには，文章構造の理解，すなわち各文が\\n他のどの文とどのような関...   \n",
       "2    # はじめに\\n\\n従来の構文解析法は基本的に句構造文法あるいは格文法をその拠り所としてきた...   \n",
       "4    # はじめに\\n\\n機械翻訳システムを使用する時, 利用者はシステム辞書に登録されていない\\...   \n",
       "5    # はじめに\\n\\n我々が目標とするのは，日本語の複文の理解システムである．このようなシステ...   \n",
       "6    # はじめに\\n\\n本論文では日本語の論説文を対象にした要約文章作成実験システム[^1] (...   \n",
       "..                                                 ...   \n",
       "527  # はじめに\\n\\n本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．\\...   \n",
       "528  # はじめに\\n\\n本研究では眼球運動に基づき文の読み時間を推定し，ヒトの文処理機構の解明を...   \n",
       "529  # はじめに\\n\\n複単語表現 (MWE)\\nは，統語的もしくは意味的な単位として扱う必要が...   \n",
       "530  # はじめに\\n\\n単語を密ベクトルで表現する単語分散表現 \\@xciteが，機械翻訳\\n\\...   \n",
       "531  # はじめに\\n\\nニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に...   \n",
       "\n",
       "                                            sec_method  \\\n",
       "0    従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...   \n",
       "2    # 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...   \n",
       "4    # 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...   \n",
       "5    # 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...   \n",
       "6    # システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...   \n",
       "..                                                 ...   \n",
       "527  # 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...   \n",
       "528  # 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...   \n",
       "529  # MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...   \n",
       "530  # 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...   \n",
       "531  # 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...   \n",
       "\n",
       "                                            sec_result  \\\n",
       "0    実験には科学雑誌サイエンスのテキスト，\\n「科学技術のためのコンピューター」(Vol.17,...   \n",
       "2    # 文解析の結果とその評価\\n\\n本手法による文解析の実験をテストサンプルの150文に対して...   \n",
       "4    # 意味属性推定精度の評価\\n\\n## 実験の条件\\n\\n表\\[tab:3\\]に示すような新...   \n",
       "5    # 制約変換による日本語複文の意味解析システム\\n\\n以上のように，意味および語用論的役割の...   \n",
       "6    # 文要約解析\\n\\n文中の修飾句を削減することにより, 一文内での要約を行う. 文の中心内...   \n",
       "..                                                 ...   \n",
       "527  # 評価実験\\n\\n本節では，WMT Metrics Shared\\nTaskにおける人手の...   \n",
       "528  # 結果と考察\\n\\n表 \\[tbl:result\\] に各モデルの分析結果を示す．詳細な結...   \n",
       "529  # 連続MWEを考慮した依存構造解析，およびVMWE認識を行うモデルの評価実験\\n\\n本章で...   \n",
       "530  # 実験設定\\n\\n提案手法の有効性を検証するために，文脈中での単語間の意味的類似度推定タス...   \n",
       "531  # 実験設定\\n\\n本稿では単語報酬モデルの性能を評価するため，日本語から英語，英語から日本...   \n",
       "\n",
       "                                        sec_conclusion  \\\n",
       "0    本論文では，手がかり表現，語連鎖，文間の類似性，という\\n表層表現中の3つ情報に基づいて文章...   \n",
       "2    # おわりに\\n\\n従来方式の構文解析では長い文の中に多く存在する並列構造を正しく認識する\\...   \n",
       "4    ## 考察\\n\\n### 訳文品質向上効果について\\n\\n最適意味属性を決定する繰り返し実験...   \n",
       "5    # おわりに\\n\\n本論文では順接の「ので」による複文の解析を例にとり，日本語の複文の意味解...   \n",
       "6    # 議論\\n\\nここでは, 機械処理した大量の要約結果の考察から得られた知見や明らかになっ\\...   \n",
       "..                                                 ...   \n",
       "527  # 分析\\n\\n## 訓練データの文対数と性能の関係\\n\\n本節では，WMT-2017のlv...   \n",
       "528  # おわりに\\n\\n本研究では，日本語の読み時間の推定のために単語埋め込みを用いることを提案...   \n",
       "529  # 結論\\n\\n本研究では，複合機能語と形容詞MWEの双方を考慮した依存構造コーパスをOnt...   \n",
       "530  # DMSEの分析\\n\\n## 語彙的換言タスクにおける意味的類似度推定手法の比較\\n\\n表...   \n",
       "531  # おわりに\\n\\n本稿ではニューラル機械翻訳における単語報酬モデルによる対訳辞書の活用手法...   \n",
       "\n",
       "                                                abs_bg  \\\n",
       "0    テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...   \n",
       "2    従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...   \n",
       "4    機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...   \n",
       "5    我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...   \n",
       "6    日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...   \n",
       "..                                                 ...   \n",
       "527  本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...   \n",
       "528  ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...   \n",
       "529  複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...   \n",
       "530  近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...   \n",
       "531  ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...   \n",
       "\n",
       "                                            abs_method  \\\n",
       "0    本論文では，知識に基づく文理解という処理を行なわずに，表層表現中の種々の情報を用いることによ...   \n",
       "2    本論文では，そのようにして検出した並列構造の情報を利用して\\n構文解析を行なう手法を示す．\\...   \n",
       "4    そこで本論文では, 利用者が登録したい日本語名詞 (複合名詞を含む) と\\n英語訳語を与える...   \n",
       "5    この際には，ゼロ代名詞の照応の解析が重要な問題となるが，文献にあるように，本論文で扱う形式の...   \n",
       "6    本研究ではこの観点から, 日本語での様々な表層的特徴をできるだけ多く利用\\nして, 日本語文...   \n",
       "..                                                 ...   \n",
       "527  そこで本研究では，文全体の大域的な情報を考慮するために，事前学習された文の分散表現を用いる機...   \n",
       "528  本論文では，この問題を解決するために単語埋め込みを用いる．skip-gram の単語埋め込み...   \n",
       "529  広範囲の連続MWEを依存構造で考慮するために，本稿では Ontonotes コーパスに対して...   \n",
       "530  そこで，本研究では各単語に対してより粒度の細かい複数の分散表現を生成するための 2 つの手法...   \n",
       "531                                                      \n",
       "\n",
       "                                            abs_result  \\\n",
       "0    実験の結果これらの情報を組み合わせて利用することにより\\n科学技術文の文章構造のかなりの部分...   \n",
       "2    各部分の係り受け解析としては，基本的に，\\n係り受け関係の非交差条件を満たした上で各文節が係...   \n",
       "4    本方式を, 新聞記事102文とソフトウエア設計書105文\\nの翻訳に必要な利用者辞書作成に適...   \n",
       "5    そこで，日本語の複文に対する形態素解析や構文解析の結果を素性構造で記述し，こ\\nの結果に対し...   \n",
       "6    本稿では実際に計算機上で試作した論説文\\n要約システムに関して, これで用いられている論説文...   \n",
       "..                                                 ...   \n",
       "527  WMT-2017 Metrics Shared Taskにおける翻訳品質のラベル付きデータセ...   \n",
       "528                                                      \n",
       "529  実験の結果，連続MWE認識ではパイプラインモデルとマルチタスクモデルがほぼ同等のF値を示し，...   \n",
       "530  単語間の意味的類似度推定タスクおよび語彙的換言タスクにおける評価実験の結果，より細かい粒度で...   \n",
       "531                                                      \n",
       "\n",
       "                                        abs_conclusion  \n",
       "0                                                       \n",
       "2    我々は，このような考え方に基づき，長い文の中に多く存在する並列構造が\\n文節列同士の類似性を...  \n",
       "4    以上の結果, 利用者辞書\\n作成への単語の登録において, 最も熟練度の要求される単語意味属性...  \n",
       "5                                                       \n",
       "6                                                       \n",
       "..                                                 ...  \n",
       "527                                                     \n",
       "528  さらに，skip-gram の単語埋め込みに基づいて構成した文節のベクトルのノルムが，日本語...  \n",
       "529                                                     \n",
       "530                                                     \n",
       "531  提案手法は，テスト時のデコーディングの際に対訳辞書に存在する単語に報酬を与えることでそれらの...  \n",
       "\n",
       "[414 rows x 15 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_df = df[df['language']=='jp']\n",
    "jp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'abs_bg': 'abs_intro'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2013502/981833588.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  jp_df.rename(columns={'abs_bg': 'abs_intro'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "jp_df.rename(columns={'abs_bg': 'abs_intro'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_df_copy = jp_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对文本列进行post processing\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def process_text(text):\n",
    "    # 删除换行符 \\n\n",
    "    text = text.replace('\\n', '')\n",
    "    \n",
    "    # 删除 {.underline}\n",
    "    text = text.replace(\"{.underline}\", \"\")\n",
    "\n",
    "    # 删除 \\underline\n",
    "    text = text.replace(\"\\\\underline\", \"\")\n",
    "    \n",
    "    # 删除 \\begin{enumerate} 和 \\end{enumerate} 以及 \\item\n",
    "    text = re.sub(r'\\\\begin\\{enumerate\\}|\\\\end\\{enumerate\\}|\\\\item', '', text)\n",
    "    \n",
    "    # 更换网址为 @url\n",
    "    text = re.sub(r'(http|https)://[^\\s]+', '@url', text)    \n",
    "    \n",
    "    # 删除::: 开头的文本（带有空格）\n",
    "    text = re.sub(r':::\\s(sent|center|table\\*|flashleft|flashright|exe|algorithm\\(ic\\)|indent|xlist|lingexample|'\n",
    "                  r'figure\\*|ex|exB|description|itembox|DEPEX|breakbox|df|enumerate|savenotes|dependency|'\n",
    "                  r'algorithm(ic)?|簡体中文)\\s?', '', text)\n",
    "    # 删除:::本身\n",
    "    text = text.replace(':::', '')\n",
    "    \n",
    "    # 匹配$$之间的数学公式\n",
    "    pattern = r'\\$\\$(.*?)\\$\\$'\n",
    "    \n",
    "    # 使用正则表达式替换数学公式为 @xlmath\n",
    "    text = re.sub(pattern, r'@xlmath', text)\n",
    "    \n",
    "    # 删除\\\n",
    "    text = text.replace('\\\\', '')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...\n",
       "2      # 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...\n",
       "4      # 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...\n",
       "5      # 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...\n",
       "6      # システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...\n",
       "                             ...                        \n",
       "527    # 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...\n",
       "528    # 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...\n",
       "529    # MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...\n",
       "530    # 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...\n",
       "531    # 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...\n",
       "Name: sec_method, Length: 414, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_df_copy['sec_method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         file_name                                         sec_method\n",
      "0    V01N01-01.tex  従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...\n",
      "2    V01N01-03.tex  # 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...\n",
      "4    V02N01-01.tex  # 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...\n",
      "5    V02N01-02.tex  # 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...\n",
      "6    V02N01-03.tex  # システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...\n",
      "..             ...                                                ...\n",
      "527  V26N03-03.tex  # 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...\n",
      "528  V26N03-04.tex  # 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...\n",
      "529  V26N04-01.tex  # MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...\n",
      "530  V26N04-02.tex  # 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...\n",
      "531  V26N04-03.tex  # 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...\n",
      "\n",
      "[414 rows x 2 columns]\n",
      "         file_name                                         sec_method\n",
      "0    V01N01-01.tex  従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...\n",
      "2    V01N01-03.tex  # 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...\n",
      "4    V02N01-01.tex  # 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...\n",
      "5    V02N01-02.tex  # 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...\n",
      "6    V02N01-03.tex  # システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...\n",
      "..             ...                                                ...\n",
      "527  V26N03-03.tex  # 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...\n",
      "528  V26N03-04.tex  # 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...\n",
      "529  V26N04-01.tex  # MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...\n",
      "530  V26N04-02.tex  # 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...\n",
      "531  V26N04-03.tex  # 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...\n",
      "\n",
      "[414 rows x 2 columns]\n",
      "         file_name                                         sec_method\n",
      "0    V01N01-01.tex  従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...\n",
      "2    V01N01-03.tex  # 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...\n",
      "4    V02N01-01.tex  # 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...\n",
      "5    V02N01-02.tex  # 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...\n",
      "6    V02N01-03.tex  # システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...\n",
      "..             ...                                                ...\n",
      "527  V26N03-03.tex  # 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...\n",
      "528  V26N03-04.tex  # 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...\n",
      "529  V26N04-01.tex  # MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...\n",
      "530  V26N04-02.tex  # 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...\n",
      "531  V26N04-03.tex  # 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...\n",
      "\n",
      "[414 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "non_string_indices = jp_df_copy[~jp_df_copy['sec_method'].apply(lambda x: isinstance(x, str))].index\n",
    "jp_df_copy.drop(non_string_indices, inplace=True)\n",
    "print(jp_df_copy[['file_name', 'sec_method']])\n",
    "non_string_indices = jp_df_copy[~jp_df_copy['sec_result'].apply(lambda x: isinstance(x, str))].index\n",
    "jp_df_copy.drop(non_string_indices, inplace=True)\n",
    "print(jp_df_copy[['file_name', 'sec_method']])\n",
    "non_string_indices = jp_df_copy[~jp_df_copy['abs_method'].apply(lambda x: isinstance(x, str))].index\n",
    "# jp_df_copy.drop(non_string_indices, inplace=True)\n",
    "print(jp_df_copy[['file_name', 'sec_method']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>etitle</th>\n",
       "      <th>jabstract</th>\n",
       "      <th>eabstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>sec_intro</th>\n",
       "      <th>sec_method</th>\n",
       "      <th>sec_result</th>\n",
       "      <th>sec_conclusion</th>\n",
       "      <th>abs_intro</th>\n",
       "      <th>abs_method</th>\n",
       "      <th>abs_result</th>\n",
       "      <th>abs_conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V01N01-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>表層表現中の情報に基づく文章構造の自動抽出</td>\n",
       "      <td>Automatic Detection of Discourse Structure by ...</td>\n",
       "      <td>テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...</td>\n",
       "      <td>To understand a text or dialogue, one must tra...</td>\n",
       "      <td>['はじめに', '文章構造のモデルと結束関係', '文章構造の自動抽出', '実験と考察'...</td>\n",
       "      <td>テキストや談話を理解するためには，文章構造の理解，すなわち各文が\\n他のどの文とどのような関...</td>\n",
       "      <td>従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...</td>\n",
       "      <td>実験には科学雑誌サイエンスのテキスト，\\n「科学技術のためのコンピューター」(Vol.17,...</td>\n",
       "      <td>本論文では，手がかり表現，語連鎖，文間の類似性，という\\n表層表現中の3つ情報に基づいて文章...</td>\n",
       "      <td>テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...</td>\n",
       "      <td>本論文では，知識に基づく文理解という処理を行なわずに，表層表現中の種々の情報を用いることによ...</td>\n",
       "      <td>実験の結果これらの情報を組み合わせて利用することにより\\n科学技術文の文章構造のかなりの部分...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V01N01-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>並列構造の検出に基づく長い日本語文の構文解析</td>\n",
       "      <td>A Syntactic Analysis Method of Long Japanese S...</td>\n",
       "      <td>従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...</td>\n",
       "      <td>Conventional parsing methods can not analyze l...</td>\n",
       "      <td>['はじめに', '並列構造の検出と文の簡単化', '係り受け解析', '文解析の結果とその...</td>\n",
       "      <td># はじめに\\n\\n従来の構文解析法は基本的に句構造文法あるいは格文法をその拠り所としてきた...</td>\n",
       "      <td># 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...</td>\n",
       "      <td># 文解析の結果とその評価\\n\\n本手法による文解析の実験をテストサンプルの150文に対して...</td>\n",
       "      <td># おわりに\\n\\n従来方式の構文解析では長い文の中に多く存在する並列構造を正しく認識する\\...</td>\n",
       "      <td>従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...</td>\n",
       "      <td>本論文では，そのようにして検出した並列構造の情報を利用して\\n構文解析を行なう手法を示す．\\...</td>\n",
       "      <td>各部分の係り受け解析としては，基本的に，\\n係り受け関係の非交差条件を満たした上で各文節が係...</td>\n",
       "      <td>我々は，このような考え方に基づき，長い文の中に多く存在する並列構造が\\n文節列同士の類似性を...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V02N01-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>日英機械翻訳における利用者登録語の意味属性の自動推定</td>\n",
       "      <td>Automatic Determination of Semantic Attributes...</td>\n",
       "      <td>機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...</td>\n",
       "      <td>User dictionaries are important for practical ...</td>\n",
       "      <td>['はじめに', 'システム辞書と利用者辞書', '意味属性推定の方法', '意味属性推定精...</td>\n",
       "      <td># はじめに\\n\\n機械翻訳システムを使用する時, 利用者はシステム辞書に登録されていない\\...</td>\n",
       "      <td># 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...</td>\n",
       "      <td># 意味属性推定精度の評価\\n\\n## 実験の条件\\n\\n表\\[tab:3\\]に示すような新...</td>\n",
       "      <td>## 考察\\n\\n### 訳文品質向上効果について\\n\\n最適意味属性を決定する繰り返し実験...</td>\n",
       "      <td>機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...</td>\n",
       "      <td>そこで本論文では, 利用者が登録したい日本語名詞 (複合名詞を含む) と\\n英語訳語を与える...</td>\n",
       "      <td>本方式を, 新聞記事102文とソフトウエア設計書105文\\nの翻訳に必要な利用者辞書作成に適...</td>\n",
       "      <td>以上の結果, 利用者辞書\\n作成への単語の登録において, 最も熟練度の要求される単語意味属性...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V02N01-02.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>主観的動機に関する意味および語用論的制約を利用した日本語複文の理解システム 〜「ので」「のに...</td>\n",
       "      <td>A zero anaphora resolution systemfor Japanese ...</td>\n",
       "      <td>我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...</td>\n",
       "      <td>Our aim is to construct a system which is able...</td>\n",
       "      <td>['はじめに', '日本語複文に関する制約および素性構造による表現', '制約変換による日本...</td>\n",
       "      <td># はじめに\\n\\n我々が目標とするのは，日本語の複文の理解システムである．このようなシステ...</td>\n",
       "      <td># 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...</td>\n",
       "      <td># 制約変換による日本語複文の意味解析システム\\n\\n以上のように，意味および語用論的役割の...</td>\n",
       "      <td># おわりに\\n\\n本論文では順接の「ので」による複文の解析を例にとり，日本語の複文の意味解...</td>\n",
       "      <td>我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...</td>\n",
       "      <td>この際には，ゼロ代名詞の照応の解析が重要な問題となるが，文献にあるように，本論文で扱う形式の...</td>\n",
       "      <td>そこで，日本語の複文に対する形態素解析や構文解析の結果を素性構造で記述し，こ\\nの結果に対し...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V02N01-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>文章内構造を複合的に利用した論説文要約システムGREEN</td>\n",
       "      <td>GREEN: An Experimental System Generating Summa...</td>\n",
       "      <td>日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...</td>\n",
       "      <td>This paper describes an experimental system fo...</td>\n",
       "      <td>['はじめに', 'システム構成', '要約文選択', '文要約解析', '段落分け解析',...</td>\n",
       "      <td># はじめに\\n\\n本論文では日本語の論説文を対象にした要約文章作成実験システム[^1] (...</td>\n",
       "      <td># システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...</td>\n",
       "      <td># 文要約解析\\n\\n文中の修飾句を削減することにより, 一文内での要約を行う. 文の中心内...</td>\n",
       "      <td># 議論\\n\\nここでは, 機械処理した大量の要約結果の考察から得られた知見や明らかになっ\\...</td>\n",
       "      <td>日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...</td>\n",
       "      <td>本研究ではこの観点から, 日本語での様々な表層的特徴をできるだけ多く利用\\nして, 日本語文...</td>\n",
       "      <td>本稿では実際に計算機上で試作した論説文\\n要約システムに関して, これで用いられている論説文...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>V26N03-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>事前学習された文の分散表現を用いた機械翻訳の自動評価</td>\n",
       "      <td>Metric for Automatic Machine Translation Evalu...</td>\n",
       "      <td>本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...</td>\n",
       "      <td>This study describes a segment-level metric fo...</td>\n",
       "      <td>['はじめに', '関連研究', '事前学習された文の分散表現を用いた機械翻訳の自動評価',...</td>\n",
       "      <td># はじめに\\n\\n本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．\\...</td>\n",
       "      <td># 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...</td>\n",
       "      <td># 評価実験\\n\\n本節では，WMT Metrics Shared\\nTaskにおける人手の...</td>\n",
       "      <td># 分析\\n\\n## 訓練データの文対数と性能の関係\\n\\n本節では，WMT-2017のlv...</td>\n",
       "      <td>本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...</td>\n",
       "      <td>そこで本研究では，文全体の大域的な情報を考慮するために，事前学習された文の分散表現を用いる機...</td>\n",
       "      <td>WMT-2017 Metrics Shared Taskにおける翻訳品質のラベル付きデータセ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>V26N03-04.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>単語埋め込みに基づくサプライザル</td>\n",
       "      <td>Surprisal through Word Embeddings</td>\n",
       "      <td>ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...</td>\n",
       "      <td>The concept of surprisal was proposed by Hale ...</td>\n",
       "      <td>['はじめに', '前提', '分析手法', '結果と考察', 'おわりに', '分析結果（...</td>\n",
       "      <td># はじめに\\n\\n本研究では眼球運動に基づき文の読み時間を推定し，ヒトの文処理機構の解明を...</td>\n",
       "      <td># 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...</td>\n",
       "      <td># 結果と考察\\n\\n表 \\[tbl:result\\] に各モデルの分析結果を示す．詳細な結...</td>\n",
       "      <td># おわりに\\n\\n本研究では，日本語の読み時間の推定のために単語埋め込みを用いることを提案...</td>\n",
       "      <td>ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...</td>\n",
       "      <td>本論文では，この問題を解決するために単語埋め込みを用いる．skip-gram の単語埋め込み...</td>\n",
       "      <td></td>\n",
       "      <td>さらに，skip-gram の単語埋め込みに基づいて構成した文節のベクトルのノルムが，日本語...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>V26N04-01.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>複単語表現を考慮した依存構造コーパスの構築と解析</td>\n",
       "      <td>Construction and Analysis of Multiword Express...</td>\n",
       "      <td>複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...</td>\n",
       "      <td>Multiword expressions (MWEs) consist of multip...</td>\n",
       "      <td>['はじめに', 'MWEを考慮した依存構造コーパスの構築', '連続MWEを考慮した依存構...</td>\n",
       "      <td># はじめに\\n\\n複単語表現 (MWE)\\nは，統語的もしくは意味的な単位として扱う必要が...</td>\n",
       "      <td># MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...</td>\n",
       "      <td># 連続MWEを考慮した依存構造解析，およびVMWE認識を行うモデルの評価実験\\n\\n本章で...</td>\n",
       "      <td># 結論\\n\\n本研究では，複合機能語と形容詞MWEの双方を考慮した依存構造コーパスをOnt...</td>\n",
       "      <td>複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...</td>\n",
       "      <td>広範囲の連続MWEを依存構造で考慮するために，本稿では Ontonotes コーパスに対して...</td>\n",
       "      <td>実験の結果，連続MWE認識ではパイプラインモデルとマルチタスクモデルがほぼ同等のF値を示し，...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>V26N04-02.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>多義語分散表現の文脈化</td>\n",
       "      <td>Contextualized Multi-Sense Word Embedding</td>\n",
       "      <td>近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...</td>\n",
       "      <td>Currently, distributed word representations ar...</td>\n",
       "      <td>['はじめに', '関連研究', '提案手法', '実験設定', '文脈中での単語間の意味的...</td>\n",
       "      <td># はじめに\\n\\n単語を密ベクトルで表現する単語分散表現 \\@xciteが，機械翻訳\\n\\...</td>\n",
       "      <td># 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...</td>\n",
       "      <td># 実験設定\\n\\n提案手法の有効性を検証するために，文脈中での単語間の意味的類似度推定タス...</td>\n",
       "      <td># DMSEの分析\\n\\n## 語彙的換言タスクにおける意味的類似度推定手法の比較\\n\\n表...</td>\n",
       "      <td>近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...</td>\n",
       "      <td>そこで，本研究では各単語に対してより粒度の細かい複数の分散表現を生成するための 2 つの手法...</td>\n",
       "      <td>単語間の意味的類似度推定タスクおよび語彙的換言タスクにおける評価実験の結果，より細かい粒度で...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>V26N04-03.tex</td>\n",
       "      <td>jp</td>\n",
       "      <td>ニューラル機械翻訳における単語報酬モデルに基づく対訳辞書の利用</td>\n",
       "      <td>Word Rewarding Model Using a Bilingual Diction...</td>\n",
       "      <td>ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...</td>\n",
       "      <td>Even though outputs of neural machine translat...</td>\n",
       "      <td>['はじめに', '注意機構付きニューラル機械翻訳', '単語報酬モデル', '実験設定',...</td>\n",
       "      <td># はじめに\\n\\nニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に...</td>\n",
       "      <td># 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...</td>\n",
       "      <td># 実験設定\\n\\n本稿では単語報酬モデルの性能を評価するため，日本語から英語，英語から日本...</td>\n",
       "      <td># おわりに\\n\\n本稿ではニューラル機械翻訳における単語報酬モデルによる対訳辞書の活用手法...</td>\n",
       "      <td>ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>提案手法は，テスト時のデコーディングの際に対訳辞書に存在する単語に報酬を与えることでそれらの...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name language  \\\n",
       "0    V01N01-01.tex       jp   \n",
       "2    V01N01-03.tex       jp   \n",
       "4    V02N01-01.tex       jp   \n",
       "5    V02N01-02.tex       jp   \n",
       "6    V02N01-03.tex       jp   \n",
       "..             ...      ...   \n",
       "527  V26N03-03.tex       jp   \n",
       "528  V26N03-04.tex       jp   \n",
       "529  V26N04-01.tex       jp   \n",
       "530  V26N04-02.tex       jp   \n",
       "531  V26N04-03.tex       jp   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                表層表現中の情報に基づく文章構造の自動抽出   \n",
       "2                               並列構造の検出に基づく長い日本語文の構文解析   \n",
       "4                           日英機械翻訳における利用者登録語の意味属性の自動推定   \n",
       "5    主観的動機に関する意味および語用論的制約を利用した日本語複文の理解システム 〜「ので」「のに...   \n",
       "6                         文章内構造を複合的に利用した論説文要約システムGREEN   \n",
       "..                                                 ...   \n",
       "527                         事前学習された文の分散表現を用いた機械翻訳の自動評価   \n",
       "528                                   単語埋め込みに基づくサプライザル   \n",
       "529                           複単語表現を考慮した依存構造コーパスの構築と解析   \n",
       "530                                        多義語分散表現の文脈化   \n",
       "531                    ニューラル機械翻訳における単語報酬モデルに基づく対訳辞書の利用   \n",
       "\n",
       "                                                etitle  \\\n",
       "0    Automatic Detection of Discourse Structure by ...   \n",
       "2    A Syntactic Analysis Method of Long Japanese S...   \n",
       "4    Automatic Determination of Semantic Attributes...   \n",
       "5    A zero anaphora resolution systemfor Japanese ...   \n",
       "6    GREEN: An Experimental System Generating Summa...   \n",
       "..                                                 ...   \n",
       "527  Metric for Automatic Machine Translation Evalu...   \n",
       "528                  Surprisal through Word Embeddings   \n",
       "529  Construction and Analysis of Multiword Express...   \n",
       "530          Contextualized Multi-Sense Word Embedding   \n",
       "531  Word Rewarding Model Using a Bilingual Diction...   \n",
       "\n",
       "                                             jabstract  \\\n",
       "0    テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...   \n",
       "2    従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...   \n",
       "4    機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...   \n",
       "5    我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...   \n",
       "6    日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...   \n",
       "..                                                 ...   \n",
       "527  本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...   \n",
       "528  ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...   \n",
       "529  複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...   \n",
       "530  近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...   \n",
       "531  ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...   \n",
       "\n",
       "                                             eabstract  \\\n",
       "0    To understand a text or dialogue, one must tra...   \n",
       "2    Conventional parsing methods can not analyze l...   \n",
       "4    User dictionaries are important for practical ...   \n",
       "5    Our aim is to construct a system which is able...   \n",
       "6    This paper describes an experimental system fo...   \n",
       "..                                                 ...   \n",
       "527  This study describes a segment-level metric fo...   \n",
       "528  The concept of surprisal was proposed by Hale ...   \n",
       "529  Multiword expressions (MWEs) consist of multip...   \n",
       "530  Currently, distributed word representations ar...   \n",
       "531  Even though outputs of neural machine translat...   \n",
       "\n",
       "                                         section_names  \\\n",
       "0    ['はじめに', '文章構造のモデルと結束関係', '文章構造の自動抽出', '実験と考察'...   \n",
       "2    ['はじめに', '並列構造の検出と文の簡単化', '係り受け解析', '文解析の結果とその...   \n",
       "4    ['はじめに', 'システム辞書と利用者辞書', '意味属性推定の方法', '意味属性推定精...   \n",
       "5    ['はじめに', '日本語複文に関する制約および素性構造による表現', '制約変換による日本...   \n",
       "6    ['はじめに', 'システム構成', '要約文選択', '文要約解析', '段落分け解析',...   \n",
       "..                                                 ...   \n",
       "527  ['はじめに', '関連研究', '事前学習された文の分散表現を用いた機械翻訳の自動評価',...   \n",
       "528  ['はじめに', '前提', '分析手法', '結果と考察', 'おわりに', '分析結果（...   \n",
       "529  ['はじめに', 'MWEを考慮した依存構造コーパスの構築', '連続MWEを考慮した依存構...   \n",
       "530  ['はじめに', '関連研究', '提案手法', '実験設定', '文脈中での単語間の意味的...   \n",
       "531  ['はじめに', '注意機構付きニューラル機械翻訳', '単語報酬モデル', '実験設定',...   \n",
       "\n",
       "                                             sec_intro  \\\n",
       "0    テキストや談話を理解するためには，文章構造の理解，すなわち各文が\\n他のどの文とどのような関...   \n",
       "2    # はじめに\\n\\n従来の構文解析法は基本的に句構造文法あるいは格文法をその拠り所としてきた...   \n",
       "4    # はじめに\\n\\n機械翻訳システムを使用する時, 利用者はシステム辞書に登録されていない\\...   \n",
       "5    # はじめに\\n\\n我々が目標とするのは，日本語の複文の理解システムである．このようなシステ...   \n",
       "6    # はじめに\\n\\n本論文では日本語の論説文を対象にした要約文章作成実験システム[^1] (...   \n",
       "..                                                 ...   \n",
       "527  # はじめに\\n\\n本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．\\...   \n",
       "528  # はじめに\\n\\n本研究では眼球運動に基づき文の読み時間を推定し，ヒトの文処理機構の解明を...   \n",
       "529  # はじめに\\n\\n複単語表現 (MWE)\\nは，統語的もしくは意味的な単位として扱う必要が...   \n",
       "530  # はじめに\\n\\n単語を密ベクトルで表現する単語分散表現 \\@xciteが，機械翻訳\\n\\...   \n",
       "531  # はじめに\\n\\nニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に...   \n",
       "\n",
       "                                            sec_method  \\\n",
       "0    従来，文章構造のモデルとしてはその基本単位の結束関係\\n(2項関係)を再帰的に組み合わせる\\...   \n",
       "2    # 並列構造の検出と文の簡単化\\n\\n## 並列構造の検出の概要\\n\\n1文中の並列する部分...   \n",
       "4    # 意味属性推定の方法\\n\\n利用者登録語の日本語表記と英語訳語が与えられたとき, 機械翻訳...   \n",
       "5    # 日本語複文に関する制約および素性構造による表現\\n\\n本論文で述べるシステムにより意味解...   \n",
       "6    # システム構成\\n\\n要約システム は̏ Sun SPARC Station I 上で, ...   \n",
       "..                                                 ...   \n",
       "527  # 事前学習された文の分散表現を用いた機械翻訳の自動評価\\n\\n従来手法に多く見られる文字や...   \n",
       "528  # 分析手法\\n\\n分析においては，いくつかの要因に基づく線形式に基づいて，読み時間をベイジ...   \n",
       "529  # MWEを考慮した依存構造コーパスの構築\\n\\n本章では，英語の複合機能語および形容詞MW...   \n",
       "530  # 提案手法\\n\\n本研究では，所与の文脈を手がかりとして，各単語に品詞 \\@xciteやト...   \n",
       "531  # 単語報酬モデル\\n\\n本章では，提案する単語報酬モデルの各要素について説明する．\\n単語...   \n",
       "\n",
       "                                            sec_result  \\\n",
       "0    実験には科学雑誌サイエンスのテキスト，\\n「科学技術のためのコンピューター」(Vol.17,...   \n",
       "2    # 文解析の結果とその評価\\n\\n本手法による文解析の実験をテストサンプルの150文に対して...   \n",
       "4    # 意味属性推定精度の評価\\n\\n## 実験の条件\\n\\n表\\[tab:3\\]に示すような新...   \n",
       "5    # 制約変換による日本語複文の意味解析システム\\n\\n以上のように，意味および語用論的役割の...   \n",
       "6    # 文要約解析\\n\\n文中の修飾句を削減することにより, 一文内での要約を行う. 文の中心内...   \n",
       "..                                                 ...   \n",
       "527  # 評価実験\\n\\n本節では，WMT Metrics Shared\\nTaskにおける人手の...   \n",
       "528  # 結果と考察\\n\\n表 \\[tbl:result\\] に各モデルの分析結果を示す．詳細な結...   \n",
       "529  # 連続MWEを考慮した依存構造解析，およびVMWE認識を行うモデルの評価実験\\n\\n本章で...   \n",
       "530  # 実験設定\\n\\n提案手法の有効性を検証するために，文脈中での単語間の意味的類似度推定タス...   \n",
       "531  # 実験設定\\n\\n本稿では単語報酬モデルの性能を評価するため，日本語から英語，英語から日本...   \n",
       "\n",
       "                                        sec_conclusion  \\\n",
       "0    本論文では，手がかり表現，語連鎖，文間の類似性，という\\n表層表現中の3つ情報に基づいて文章...   \n",
       "2    # おわりに\\n\\n従来方式の構文解析では長い文の中に多く存在する並列構造を正しく認識する\\...   \n",
       "4    ## 考察\\n\\n### 訳文品質向上効果について\\n\\n最適意味属性を決定する繰り返し実験...   \n",
       "5    # おわりに\\n\\n本論文では順接の「ので」による複文の解析を例にとり，日本語の複文の意味解...   \n",
       "6    # 議論\\n\\nここでは, 機械処理した大量の要約結果の考察から得られた知見や明らかになっ\\...   \n",
       "..                                                 ...   \n",
       "527  # 分析\\n\\n## 訓練データの文対数と性能の関係\\n\\n本節では，WMT-2017のlv...   \n",
       "528  # おわりに\\n\\n本研究では，日本語の読み時間の推定のために単語埋め込みを用いることを提案...   \n",
       "529  # 結論\\n\\n本研究では，複合機能語と形容詞MWEの双方を考慮した依存構造コーパスをOnt...   \n",
       "530  # DMSEの分析\\n\\n## 語彙的換言タスクにおける意味的類似度推定手法の比較\\n\\n表...   \n",
       "531  # おわりに\\n\\n本稿ではニューラル機械翻訳における単語報酬モデルによる対訳辞書の活用手法...   \n",
       "\n",
       "                                             abs_intro  \\\n",
       "0    テキストや談話を理解するためには，まずその文章構造を理解する必要があ\\nる．文章構造に関する...   \n",
       "2    従来の構文解析法は十分な精度の解析結果を得ることができず，とくに長い文の解析が困難であった．...   \n",
       "4    機械翻訳システムを使用して現実の文書を翻訳する場合, 通常, \\n翻訳対象文書に合った利用者...   \n",
       "5    我々は，接続助詞「ので」による順接の複文と接続助詞「のに」による逆接の複\\n文を対象とする理...   \n",
       "6    日本語文章要約システムについて報告する. 一般に, 質の良い文章要約を\\n行うためには, あ...   \n",
       "..                                                 ...   \n",
       "527  本稿では，参照文を用いた文単位での機械翻訳自動評価手法について述べる．現在のデファクトスタン...   \n",
       "528  ヒトの文処理のモデル化として Hale によりサプライザルが提案されている．サプライザルは文...   \n",
       "529  複単語表現 (MWE) は統語的または意味的な非構成性を有する複数の単語からなるまとまりであ...   \n",
       "530  近年，多くの自然言語処理タスクにおいて単語分散表現が利用されている．しかし，各単語に 1 つ...   \n",
       "531  ニューラル機械翻訳は従来手法の句に基づく統計的機械翻訳に比べて，文法的に流暢な翻訳を出力でき...   \n",
       "\n",
       "                                            abs_method  \\\n",
       "0    本論文では，知識に基づく文理解という処理を行なわずに，表層表現中の種々の情報を用いることによ...   \n",
       "2    本論文では，そのようにして検出した並列構造の情報を利用して\\n構文解析を行なう手法を示す．\\...   \n",
       "4    そこで本論文では, 利用者が登録したい日本語名詞 (複合名詞を含む) と\\n英語訳語を与える...   \n",
       "5    この際には，ゼロ代名詞の照応の解析が重要な問題となるが，文献にあるように，本論文で扱う形式の...   \n",
       "6    本研究ではこの観点から, 日本語での様々な表層的特徴をできるだけ多く利用\\nして, 日本語文...   \n",
       "..                                                 ...   \n",
       "527  そこで本研究では，文全体の大域的な情報を考慮するために，事前学習された文の分散表現を用いる機...   \n",
       "528  本論文では，この問題を解決するために単語埋め込みを用いる．skip-gram の単語埋め込み...   \n",
       "529  広範囲の連続MWEを依存構造で考慮するために，本稿では Ontonotes コーパスに対して...   \n",
       "530  そこで，本研究では各単語に対してより粒度の細かい複数の分散表現を生成するための 2 つの手法...   \n",
       "531                                                      \n",
       "\n",
       "                                            abs_result  \\\n",
       "0    実験の結果これらの情報を組み合わせて利用することにより\\n科学技術文の文章構造のかなりの部分...   \n",
       "2    各部分の係り受け解析としては，基本的に，\\n係り受け関係の非交差条件を満たした上で各文節が係...   \n",
       "4    本方式を, 新聞記事102文とソフトウエア設計書105文\\nの翻訳に必要な利用者辞書作成に適...   \n",
       "5    そこで，日本語の複文に対する形態素解析や構文解析の結果を素性構造で記述し，こ\\nの結果に対し...   \n",
       "6    本稿では実際に計算機上で試作した論説文\\n要約システムに関して, これで用いられている論説文...   \n",
       "..                                                 ...   \n",
       "527  WMT-2017 Metrics Shared Taskにおける翻訳品質のラベル付きデータセ...   \n",
       "528                                                      \n",
       "529  実験の結果，連続MWE認識ではパイプラインモデルとマルチタスクモデルがほぼ同等のF値を示し，...   \n",
       "530  単語間の意味的類似度推定タスクおよび語彙的換言タスクにおける評価実験の結果，より細かい粒度で...   \n",
       "531                                                      \n",
       "\n",
       "                                        abs_conclusion  \n",
       "0                                                       \n",
       "2    我々は，このような考え方に基づき，長い文の中に多く存在する並列構造が\\n文節列同士の類似性を...  \n",
       "4    以上の結果, 利用者辞書\\n作成への単語の登録において, 最も熟練度の要求される単語意味属性...  \n",
       "5                                                       \n",
       "6                                                       \n",
       "..                                                 ...  \n",
       "527                                                     \n",
       "528  さらに，skip-gram の単語埋め込みに基づいて構成した文節のベクトルのノルムが，日本語...  \n",
       "529                                                     \n",
       "530                                                     \n",
       "531  提案手法は，テスト時のデコーディングの際に対訳辞書に存在する単語に報酬を与えることでそれらの...  \n",
       "\n",
       "[414 rows x 15 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_df_copy['sec_intro'] = jp_df_copy['sec_intro'].apply(process_text)\n",
    "jp_df_copy['abs_intro'] = jp_df_copy['abs_intro'].apply(process_text)\n",
    "\n",
    "jp_df_copy['sec_method'] = jp_df_copy['sec_method'].apply(process_text)\n",
    "jp_df_copy['abs_method'] = jp_df_copy['abs_method'].apply(process_text)\n",
    "\n",
    "jp_df_copy['sec_result'] = jp_df_copy['sec_result'].apply(process_text)\n",
    "jp_df_copy['abs_result'] = jp_df_copy['abs_result'].apply(process_text)\n",
    "\n",
    "jp_df_copy['sec_conclusion'] = jp_df_copy['sec_conclusion'].apply(process_text)\n",
    "jp_df_copy['abs_conclusion'] = jp_df_copy['abs_conclusion'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'その際，最良解釈を求めるために必要な処理だけを行ない，それ以外の処理の\\n実行は必要が生じるまで保留することによって無駄な処理を避ける．\\n保留した処理を必要に応じて再開することによって，最良解釈以外の解釈も選\\nび出せる．'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_df['abs_conclusion'][39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'その際，最良解釈を求めるために必要な処理だけを行ない，それ以外の処理の実行は必要が生じるまで保留することによって無駄な処理を避ける．保留した処理を必要に応じて再開することによって，最良解釈以外の解釈も選び出せる．'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_df_copy['abs_conclusion'][39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_df_copy.to_csv('NLP_JP_CORPUS_jp_only_processed.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
